#!/usr/bin/env python3
# -*- coding:utf-8 -*-

import os
import signal
import argparse
import json
import tempfile
import shutil
import tarfile
import codecs

DEFAULT_PIPELINE = [
    [
      'agora_results.pipes.results.do_tallies',
      {}
    ],
    [
      "agora_results.pipes.sort.sort_non_iterative",
      {
        "question_indexes": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
      }
    ]
]

def extract_tally(fpath):
    '''
    extracts the tally and loads the results into a file for convenience
    '''
    extract_dir = tempfile.mkdtemp()
    tar = tarfile.open(fpath)
    tar.extractall(extract_dir)
    tar.close()
    return extract_dir

def print_csv(data, separator):
    counts = data['results']['questions']
    for question, i in zip(counts, range(len(counts))):
        if question['tally_type'] not in ["plurality-at-large", "borda", "borda-nauru"]:
            continue

        print(separator.join(["Question"]))
        print(separator.join(["Number", "Title"]))
        print(separator.join([str(i + 1), question['title']]))
        print(separator*2)

        print(separator.join(["Totals"]))

        print(separator.join(["Total votes", str(data['results']['total_votes'])]))
        print(separator.join(["Blank votes", str(question['totals']['blank_votes'])]))
        print(separator.join(["Null votes", str(question['totals']['null_votes'])]))
        print(separator.join(["Valid votes", str(question['totals']['valid_votes'])]))
        print(separator*2)

        print(separator.join(["Answers"]))
        print(separator.join(["Id", "Text", "Category", "Total votes", "Winner position"]))
        for answer in question['answers']:
            print(separator.join([
                str(answer['id']),
                answer['text'],
                answer['category'],
                str(answer['total_count']),
                str(answer['winner_position'])]))


def pretty_print(data):
    from agora_results.pipes.pretty_print import pretty_print_not_iterative
    pretty_print_not_iterative([data])

def print_results(data, output_format):
  '''
  print results in the specified output format
  '''
  if output_format == "json":
    print(json.dumps(
        data['results'],
        indent=4,
        ensure_ascii=False,
        sort_keys=True,
        separators=(',', ': ')))
  elif output_format == "csv":
      print_csv(data, separator=",")
  elif output_format == "tsv":
      print_csv(data, separator="\t")
  elif output_format == "pretty":
      pretty_print(data)

def func_path_sanity_checks(func_path):
    '''
    Check that the func path is valid and reasonably secure
    '''
    values = func_path.split(".")
    if " " in func_path or len(values) == 0 or len(values) > 4 or\
        values[0] != "agora_results" or values[1] != "pipes":
        raise Exception()

    for val in values:
        if len(val) == 0 or val.startswith("_"):
            raise Exception()

def execute_pipeline(pipeline_info, data_list):
    '''
    Execute a pipeline of options. pipeline_info must be a list of
    pairs. Each pair contains (pipe_func_path, params), where pipe_func_path is
    the path to the module and a function name, and params is either
    None or a dictionary with extra parameters accepted by the function.

    Pipeline functions must accept always at least one parameter, 'data', which
    will initially be the data parameter of this function, but each function is
    allow to modify it as a way to process the data.

    The other parameters of the function will be the "params" specified for
    that function in 'pipeline_info', which can either be None or a dict, and
    the format is of your choice as a developer.
    '''
    for func_path, kwargs in pipeline_info:
        # get access to the function
        func_path_sanity_checks(func_path)
        func_name = func_path.split(".")[-1]
        module = __import__(
            ".".join(func_path.split(".")[:-1]), globals(), locals(),
            [func_name], 0)
        fargs = dict(data_list=data_list)
        if kwargs is not None:
            fargs.update(kwargs)
        ret = getattr(module, func_name)(**fargs)

    return data_list

def main():
    parser = argparse.ArgumentParser(description='Process and show tally '
                                     'results. If no config is specified, it '
                                     'parses results in raw.')
    parser.add_argument('-t', '--tally', nargs='+', help='tally path')
    parser.add_argument('-x', '--tar',   nargs='?', help='tar tallies output path')
    parser.add_argument('-c', '--config', help='config path')
    parser.add_argument('-s', '--stdout', help='print output to stdout',
        action='store_true')
    parser.add_argument('-o', '--output-format', help='select the output format',
        default="json", choices=["json", "csv", "tsv", "pretty"])
    pargs = parser.parse_args()

    if pargs.config is not None:
      with codecs.open(pargs.config, 'r', encoding="utf-8") as f:
          pipeline_info = json.loads(f.read())
    else:
      pipeline_info = DEFAULT_PIPELINE
    data_list = []

    # remove files on abrupt external exit signal
    def sig_handler(signum, frame):
        if not pargs.stdout:
            print("\nTerminating: deleting temporal files..")
        for data in data_list:
            if os.path.exists(data["extract_dir"]):
                shutil.rmtree(data["extract_dir"])
        exit(1)
    signal.signal(signal.SIGTERM, sig_handler)
    signal.signal(signal.SIGINT, sig_handler)

    try:
        # extract each tally, before starting the pipeline, and put the tally
        # relevant data in a list that is processed by the pipeline
        for tally in pargs.tally:
            extract_dir = extract_tally(tally)
            if not pargs.stdout:
                print("Extracted tally %s in %s.." % (tally, extract_dir))
            data_list.append(dict(extract_dir=extract_dir))

        execute_pipeline(pipeline_info, data_list)
        if pargs.stdout and len(data_list) > 0 and 'results' in data_list[0]:
          print_results(data_list[0], pargs.output_format)
        data = ""

        # tar tallies
        if pargs.tar:
            from agora_results.utils.tallies import tar_tallies
            for tally in pargs.tally:
                tar_tallies(data_list[0], pipeline_info, tally, pargs.tar)

    finally:
        if not pargs.stdout:
            print("Deleting temporal files..")
        for data in data_list:
            if os.path.exists(data["extract_dir"]):
                shutil.rmtree(data["extract_dir"])

if __name__ == '__main__':
    main()
